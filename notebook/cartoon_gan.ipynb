{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "print('TensorFLow', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = 256, 256\n",
    "filters = 64\n",
    "output_stride = 16\n",
    "h_output = H // output_stride\n",
    "w_output = W // output_stride\n",
    "batch_size = 64\n",
    "latent_dim = 100\n",
    "display_noise = tf.random.normal(shape=[16, latent_dim], mean=0, stddev=1)\n",
    "w_init = tf.initializers.glorot_uniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img)\n",
    "    img = tf.image.resize(img, size=[H, W])[..., :3]\n",
    "    img /= 127.5\n",
    "    img -= 1\n",
    "    return img\n",
    "\n",
    "\n",
    "image_list = glob('cartoonset100k/*/*.png')\n",
    "print('Found {} images'.format(len(image_list)))\n",
    "\n",
    "image_dataset = tf.data.Dataset.from_tensor_slices(image_list)\n",
    "image_dataset = image_dataset.shuffle(buffer_size=10240)\n",
    "image_dataset = image_dataset.map(\n",
    "    load_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "image_dataset = image_dataset.batch(batch_size)\n",
    "image_dataset = image_dataset.prefetch(\n",
    "    buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv_block(input_tensor, num_filters, kernel_size, strides, bn=True):\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=num_filters,\n",
    "                                        kernel_initializer=w_init,\n",
    "                                        kernel_size=kernel_size,\n",
    "                                        padding='same',\n",
    "                                        strides=strides, use_bias=False if bn else True)(input_tensor)\n",
    "    if bn:\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, num_filters, kernel_size, padding='same', strides=2, bn=True, activation=True):\n",
    "    x = tf.keras.layers.Conv2D(filters=num_filters,\n",
    "                               kernel_initializer=w_init,\n",
    "                               kernel_size=kernel_size,\n",
    "                               padding=padding,\n",
    "                               strides=strides, use_bias=False if bn else True)(input_tensor)\n",
    "    if bn:\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim=100):\n",
    "    f = [2**i for i in range(5)][::-1]\n",
    "    noise = tf.keras.layers.Input(\n",
    "        shape=(latent_dim,), name='generator_noise_input')\n",
    "    x = tf.keras.layers.Dense(f[0] * filters * h_output * w_output)(noise)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Reshape(\n",
    "        target_shape=[h_output, w_output, 16 * filters])(x)\n",
    "    for i in range(1, 5):\n",
    "        x = deconv_block(x,\n",
    "                         num_filters=f[i] * filters,\n",
    "                         kernel_size=5,\n",
    "                         strides=2,\n",
    "                         bn=True)\n",
    "    x = deconv_block(x,\n",
    "                     num_filters=3,\n",
    "                     kernel_size=3,\n",
    "                     strides=1,\n",
    "                     bn=False)\n",
    "    fake_output = tf.keras.layers.Activation(\n",
    "        'tanh', name='generator_output')(x)\n",
    "    return tf.keras.Model(inputs=[noise],\n",
    "                          outputs=[fake_output],\n",
    "                          name='Generator')\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    image_input = tf.keras.layers.Input(\n",
    "        shape=[H, W, 3], name='discriminator_image_input')\n",
    "    f = [2**i for i in range(4)]\n",
    "    x = conv_block(\n",
    "        image_input, num_filters=f[0] * filters, kernel_size=5, strides=2, bn=False)\n",
    "    for i in range(1, 4):\n",
    "        x = conv_block(x,\n",
    "                       num_filters=f[0] * filters,\n",
    "                       kernel_size=5,\n",
    "                       strides=2,\n",
    "                       bn=True)\n",
    "    x = conv_block(x,\n",
    "                   num_filters=1,\n",
    "                   kernel_size=h_output,\n",
    "                   padding='valid',\n",
    "                   strides=1,\n",
    "                   bn=False, activation=False)\n",
    "    classification_logits = tf.keras.layers.Reshape(target_shape=[1])(x)\n",
    "    return tf.keras.Model(inputs=[image_input], outputs=[classification_logits], name='Discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator(latent_dim)\n",
    "discriminator = build_discriminator()\n",
    "bce_loss_fn = tf.keras.losses.BinaryCrossentropy(\n",
    "    from_logits=True, label_smoothing=0.1)\n",
    "d_optimizer = tf.keras.optimizers.Adam(learning_rate=0.00025, beta_1=0.5)\n",
    "g_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_D(real_logits, fake_logits):\n",
    "    '''Discriminator loss'''\n",
    "    real_loss = 0.5 * bce_loss_fn(tf.ones_like(real_logits), real_logits)\n",
    "    fake_loss = 0.5 * bce_loss_fn(tf.zeros_like(fake_logits), fake_logits)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "\n",
    "def loss_G(fake_logits):\n",
    "    '''Generator loss'''\n",
    "    loss = bce_loss_fn(tf.ones_like(fake_logits), fake_logits)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def loss_D_real(real_logits):\n",
    "    '''Discriminator loss, real images'''\n",
    "    real_loss = bce_loss_fn(tf.ones_like(real_logits), real_logits)\n",
    "    return real_loss\n",
    "\n",
    "\n",
    "def loss_D_fake(fake_logits):\n",
    "    '''Discriminator loss, fake images'''\n",
    "    fake_loss = bce_loss_fn(tf.zeros_like(fake_logits), fake_logits)\n",
    "    return fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def training_step(images):\n",
    "    noise = tf.random.normal(shape=[batch_size, latent_dim], mean=0, stddev=1)\n",
    "\n",
    "    with tf.GradientTape() as r_tape:\n",
    "        real_logits = discriminator(images, training=True)\n",
    "        discriminator_loss_real = loss_D_real(real_logits)\n",
    "        discriminator_gradients_real = r_tape.gradient(\n",
    "            discriminator_loss_real, discriminator.trainable_variables)\n",
    "        d_optimizer.apply_gradients(\n",
    "            zip(discriminator_gradients_real, discriminator.trainable_variables))\n",
    "\n",
    "    with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
    "        fake_logits = discriminator(\n",
    "            generator(noise, training=True), training=True)\n",
    "\n",
    "        discriminator_loss_fake = loss_D_fake(fake_logits)\n",
    "        generator_loss = loss_G(fake_logits)\n",
    "\n",
    "        discriminator_gradients_fake = d_tape.gradient(\n",
    "            discriminator_loss_fake, discriminator.trainable_variables)\n",
    "        generator_gradients = g_tape.gradient(\n",
    "            generator_loss, generator.trainable_variables)\n",
    "\n",
    "        d_optimizer.apply_gradients(\n",
    "            zip(discriminator_gradients_fake, discriminator.trainable_variables))\n",
    "        g_optimizer.apply_gradients(\n",
    "            zip(generator_gradients, generator.trainable_variables))\n",
    "\n",
    "    return generator_loss, discriminator_loss_real, discriminator_loss_fake\n",
    "\n",
    "def save_generated_images(noise, epoch=None):\n",
    "    images = generator(noise)\n",
    "    images = tf.clip_by_value((images + 1) * 127.5, 0, 255).numpy()\n",
    "    for i in range(16):\n",
    "        cv2.imwrite(f'train_viz/{i}_{epoch}.png',\n",
    "                    cv2.cvtColor(images[i], cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=30, save_every=3, steps=None):\n",
    "    batch_losses = {'g_loss': [], 'd_loss': []}\n",
    "    epoch_losses = {'g_loss': [], 'd_loss': []}\n",
    "    for ep in range(epochs):\n",
    "        running_loss = {'g_loss': [], 'd_loss': []}\n",
    "        for step, images in enumerate(image_dataset):\n",
    "            batch_g_loss, batch_d_loss_real, batch_d_loss_fake = training_step(images)\n",
    "            batch_d_loss = batch_d_loss_real + batch_d_loss_fake\n",
    "            running_loss['g_loss'].append(batch_g_loss.numpy())\n",
    "            running_loss['d_loss'].append(batch_d_loss.numpy())\n",
    "            if (step + 1) % 25 == 0:\n",
    "                print(\n",
    "                    f'||epoch {ep+1}/{epochs} step {step+1}/{steps}|G_LOSS : {batch_g_loss:.3f}|D_LOSS : {batch_d_loss:.3f}||')\n",
    "            if (step + 1) % 250 == 0:\n",
    "                save_generated_images(display_noise, epoch=f'{ep+1}_{step+1}')\n",
    "            tf.summary.scalar(\"generator_batch_loss\",\n",
    "                              batch_g_loss, step=step + 1)\n",
    "            tf.summary.scalar(\"discriminator_batch_loss_total\",\n",
    "                              batch_d_loss, step=step + 1)\n",
    "            tf.summary.scalar(\"discriminator_batch_loss_real\",\n",
    "                              batch_d_loss_real, step=step + 1)\n",
    "            tf.summary.scalar(\"discriminator_batch_loss_fake\",\n",
    "                              batch_d_loss_fake, step=step + 1)\n",
    "            writer.flush()\n",
    "        batch_losses['g_loss'].extend(running_loss['g_loss'])\n",
    "        batch_losses['d_loss'].extend(running_loss['d_loss'])\n",
    "        epoch_losses['g_loss'].append(np.mean(running_loss['g_loss']))\n",
    "        epoch_losses['d_loss'].append(np.mean(running_loss['d_loss']))\n",
    "        if (ep + 1) % save_every == 0:\n",
    "            print(f'||saving weights for epoch : {ep+1}||')\n",
    "            generator.save_weights(f'model_files/generator_weights_{ep+1}.h5')\n",
    "            discriminator.save_weights(\n",
    "                f'model_files/discriminator_weights_{ep+1}.h5')\n",
    "    return batch_losses, epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.create_file_writer('logs')\n",
    "with writer.as_default():\n",
    "    steps_per_epoch = len(image_list)//batch_size\n",
    "    batch_losses, epoch_losses = train(25, 3, steps_per_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
